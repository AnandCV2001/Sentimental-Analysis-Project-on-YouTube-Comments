{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnandCV2001/Sentimental-Analysis-Project-on-YouTube-Comments/blob/main/Final_Sentment_Analysis_Project_25_02_2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  **Sentiment analysis Project for YouTube Comments**"
      ],
      "metadata": {
        "id": "Akc0tbEMOcWV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*** Importing python libraries**"
      ],
      "metadata": {
        "id": "_PWG5SeGO9K7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUONX0C6X4Gv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import googleapiclient.discovery\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*** Code to scrape Youtube comments bold text bold text**"
      ],
      "metadata": {
        "id": "QMz3yASrPsZu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1u5W4rSbO2xH"
      },
      "outputs": [],
      "source": [
        "# Code to scrape Youtube comments\n",
        "api_service_name = \"youtube\"\n",
        "api_version = \"v3\"\n",
        "DEVELOPER_KEY = \"Enter_your_API_key\" # Dont share your YouTube api to anyone\n",
        "\n",
        "youtube = googleapiclient.discovery.build(\n",
        "    api_service_name, api_version, developerKey=DEVELOPER_KEY)\n",
        "\n",
        "request = youtube.commentThreads().list(\n",
        "    part=\"snippet\",\n",
        "    videoId=\"Enter_the_youtube_video_link\", # Dont paste the whole link , just take the portion after =\n",
        "    maxResults=150                          # Eg : https://www.youtube.com/watch?v=xrW52jF_uKA&t=20s from this link just take xrW52jF_uKA , this portion .\n",
        ")\n",
        "response = request.execute()\n",
        "\n",
        "comments = []\n",
        "\n",
        "for item in response['items']:\n",
        "    comment = item['snippet']['topLevelComment']['snippet']\n",
        "    comments.append([\n",
        "        comment['authorDisplayName'],\n",
        "        comment['publishedAt'],\n",
        "        comment['updatedAt'],\n",
        "        comment['likeCount'],\n",
        "        comment['textDisplay']\n",
        "    ])\n",
        "\n",
        "df = pd.DataFrame(comments, columns=['author', 'published_at', 'updated_at', 'like_count', 'text'])\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBdFUuB-boLf"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siMC3aH1cFJi"
      },
      "outputs": [],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*** Checking weather there are null values**"
      ],
      "metadata": {
        "id": "UuxY3IZVQWLi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dW88VomcSMD"
      },
      "outputs": [],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*** Droping the unwanted columns**"
      ],
      "metadata": {
        "id": "uLnmjFM9Qko3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLV8XdH3cfIt"
      },
      "outputs": [],
      "source": [
        "df.drop(['author','published_at','updated_at','like_count'],axis=1,inplace=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*** Downloading NLTK Resources**"
      ],
      "metadata": {
        "id": "zLTWZV0sW66u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGtrUChnd2ch"
      },
      "outputs": [],
      "source": [
        "nltk.download('stopwords') #It is used to remove stopwords\n",
        "nltk.download('punkt') # It is used for tokenization\n",
        "nltk.download('wordnet') # It is used for lematization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_QgDVMcJKM7"
      },
      "outputs": [],
      "source": [
        "comment=df.text\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*** Tokenization**"
      ],
      "metadata": {
        "id": "wD-VK9RqYr6C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJ9JX9QJNiUB"
      },
      "outputs": [],
      "source": [
        "# Tokenization : It helps to convert raw text into a format that can be easily processed and analyzed by machines.\n",
        "from nltk import TweetTokenizer #WordTokenizer\n",
        "tk=TweetTokenizer()\n",
        "comment=comment.apply(lambda x:tk.tokenize(x)).apply(lambda x:\" \".join(x))\n",
        "comment"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*** Removing special charactors**"
      ],
      "metadata": {
        "id": "TcghvQxtY05j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfMFD3fWNyrI"
      },
      "outputs": [],
      "source": [
        "#Regular Expressinon (It is used for removing special charactors)\n",
        "import re\n",
        "comment=comment.str.replace('[^a-zA-Z0-9]+',' ')\n",
        "comment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNXW_GJWOd4r"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "comment=comment.apply(lambda x:' '.join([w for w in word_tokenize(x) if len(w)>=3]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*** Stemming**"
      ],
      "metadata": {
        "id": "D7aV7ZUEZ20p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wt5qcbhgPVS9"
      },
      "outputs": [],
      "source": [
        "# Stemming is the process of reducing words to their root or base form\n",
        "from nltk.stem import SnowballStemmer\n",
        "stemmer=SnowballStemmer('english')\n",
        "comment=comment.apply(lambda x:[stemmer.stem(i.lower()) for i in tk.tokenize(x)]).apply(lambda x:' '.join(x))\n",
        "comment"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*** Removing Stopwords**"
      ],
      "metadata": {
        "id": "m8tg8nopZ9Yr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzLlRdt0PjBv"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop=stopwords.words('english')\n",
        "comment=comment.apply(lambda x:[i for i in word_tokenize(x) if i not in stop]).apply(lambda x:' '.join(x))\n",
        "comment"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*** Vectorization**"
      ],
      "metadata": {
        "id": "vbfitIE3aPjO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ip0bcpgYQgrG"
      },
      "outputs": [],
      "source": [
        "#Vectozisation - converting words into numbers\n",
        "#Tfidf - Tearm frequency inverse documrnt frequency\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vec=TfidfVectorizer()\n",
        "data=vec.fit_transform(comment)\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMz0UEElYDHx"
      },
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*** Sentiment analysis**"
      ],
      "metadata": {
        "id": "LE7v4eH2amnW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKX8DVeyjRnR"
      },
      "outputs": [],
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "def get_sentiment(data):\n",
        "    analysis = TextBlob(data)\n",
        "    # Polarity ranges from -1 (negative) to 1 (positive)\n",
        "    polarity = analysis.sentiment.polarity\n",
        "    if polarity > 0:\n",
        "        return 'positive'\n",
        "    elif polarity < 0:\n",
        "        return 'negative'\n",
        "    else:\n",
        "        return 'neutral'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiments = []\n",
        "for i, comment in enumerate(comment):\n",
        "    sentiment = get_sentiment(comment)\n",
        "    sentiments.append({\"Comment\": comment, \"Sentiment\": sentiment})\n",
        "\n",
        "# Print sentiments\n",
        "for sentiment in sentiments:\n",
        "    print(sentiment)"
      ],
      "metadata": {
        "id": "65eTxMDTGwhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = [\"Comment\", \"Sentiment\"]\n",
        "result = pd.DataFrame(sentiments, columns=columns)\n",
        "result"
      ],
      "metadata": {
        "id": "yYJMSxnqJ_wc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.head()"
      ],
      "metadata": {
        "id": "NKL4WYnC3JoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.tail()"
      ],
      "metadata": {
        "id": "MOcNqmfE3OKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the occurrences of each sentiment\n",
        "sentiment_counts = result['Sentiment'].value_counts()\n",
        "\n",
        "# Convert the series to a DataFrame\n",
        "sentiment_counts_df = sentiment_counts.reset_index()\n",
        "sentiment_counts_df.columns = ['Sentiment', 'count']\n",
        "\n",
        "df = pd.DataFrame(result)"
      ],
      "metadata": {
        "id": "f_YGft_xk_st"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*** Pie Chart**"
      ],
      "metadata": {
        "id": "U4gbcessbbVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df = pd.DataFrame(result)\n",
        "\n",
        "# Count the occurrences of each sentiment category\n",
        "# sentiment_counts = df['Sentiment'].value_counts()\n",
        "\n",
        "# Plotting the pie chart\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.pie(sentiment_counts, labels=sentiment_counts.index, autopct='%1.1f%%', startangle=140)\n",
        "plt.title('Sentiment Distribution : Pie Plot')\n",
        "plt.axis('equal')\n",
        "\n",
        "colors = ['orange', 'green', 'blue']\n",
        "labels = ['Positive', 'Negative', 'Neutral']\n",
        "patches = [plt.Rectangle((0,0),1,1, color=color) for color in colors]\n",
        "plt.legend(patches, labels, loc='lower right')\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TTS09hdeqLNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*** Bar Chart**"
      ],
      "metadata": {
        "id": "seVkQgCTbqHI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df = pd.DataFrame(result)\n",
        "\n",
        "# Count the occurrences of each sentiment category\n",
        "#sentiment_counts = df['Sentiment'].value_counts()\n",
        "\n",
        "# Plotting the bar chart\n",
        "plt.figure(figsize=(8, 6))\n",
        "sentiment_counts.plot(kind='bar', color=['green', 'red', 'blue'])\n",
        "plt.title('Overall Sentiment Distribution : Bar Plot ')\n",
        "plt.xlabel('Sentiment')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=0)\n",
        "\n",
        "colors = ['red', 'green', 'blue']\n",
        "labels = ['Positive', 'Negative', 'Neutral']\n",
        "patches = [plt.Rectangle((0,0),1,1, color=color) for color in colors]\n",
        "plt.legend(patches, labels, loc='upper right')\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Et3RfCAW1Ksn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*** Donut Chart**"
      ],
      "metadata": {
        "id": "m590GFI_b5vO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df = pd.DataFrame(result)\n",
        "\n",
        "# Count the occurrences of each sentiment category\n",
        "# sentiment_counts = df['Sentiment'].value_counts()\n",
        "\n",
        "# Plotting the donut chart\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.pie(sentiment_counts, labels=sentiment_counts.index, autopct='%1.1f%%', startangle=140, wedgeprops=dict(width=0.3))\n",
        "plt.title('Sentiment Distribution : Donut Plot')\n",
        "# Draw a white circle at the center to make it look like a donut\n",
        "centre_circle = plt.Circle((0, 0), 0.2, color='white', fc='white', linewidth=1.25)\n",
        "fig = plt.gcf()\n",
        "fig.gca().add_artist(centre_circle)\n",
        "colors = ['orange', 'green', 'blue']\n",
        "labels = ['Positive', 'Negative', 'Neutral']\n",
        "patches = [plt.Rectangle((0,0),1,1, color=color) for color in colors]\n",
        "plt.legend(patches, labels, loc='lower right')\n",
        "plt.axis('equal')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HEfYdoBl1gXT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmFQrsk55lsopRzHk038+Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}